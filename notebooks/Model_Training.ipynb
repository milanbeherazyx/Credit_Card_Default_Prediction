{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a0545a-ac1b-46fe-9c69-4fc344937422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.ticker as mtick  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a36d9f-dabb-40b0-9593-f60fea490c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>DEFAULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004.0</td>\n",
       "      <td>31237.0</td>\n",
       "      <td>15980.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8979.0</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>8998.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20878.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>19357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774.0</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>85900.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>52964.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535.0</td>\n",
       "      <td>32428.0</td>\n",
       "      <td>15313.0</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0        20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1       120000.0    2          2         2   26     -1      2      0      0   \n",
       "2        90000.0    2          2         2   34      0      0      0      0   \n",
       "3        50000.0    2          2         1   37      0      0      0      0   \n",
       "4        50000.0    1          2         1   57     -1      0     -1      0   \n",
       "...          ...  ...        ...       ...  ...    ...    ...    ...    ...   \n",
       "29995   220000.0    1          3         1   39      0      0      0      0   \n",
       "29996   150000.0    1          3         2   43     -1     -1     -1     -1   \n",
       "29997    30000.0    1          2         2   37      4      3      2     -1   \n",
       "29998    80000.0    1          3         1   41      1     -1      0      0   \n",
       "29999    50000.0    1          2         1   46      0      0      0      0   \n",
       "\n",
       "       PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0         -2  ...        0.0        0.0        0.0       0.0     689.0   \n",
       "1          0  ...     3272.0     3455.0     3261.0       0.0    1000.0   \n",
       "2          0  ...    14331.0    14948.0    15549.0    1518.0    1500.0   \n",
       "3          0  ...    28314.0    28959.0    29547.0    2000.0    2019.0   \n",
       "4          0  ...    20940.0    19146.0    19131.0    2000.0   36681.0   \n",
       "...      ...  ...        ...        ...        ...       ...       ...   \n",
       "29995      0  ...    88004.0    31237.0    15980.0    8500.0   20000.0   \n",
       "29996      0  ...     8979.0     5190.0        0.0    1837.0    3526.0   \n",
       "29997      0  ...    20878.0    20582.0    19357.0       0.0       0.0   \n",
       "29998      0  ...    52774.0    11855.0    48944.0   85900.0    3409.0   \n",
       "29999      0  ...    36535.0    32428.0    15313.0    2078.0    1800.0   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  DEFAULT  \n",
       "0           0.0       0.0       0.0       0.0        1  \n",
       "1        1000.0    1000.0       0.0    2000.0        1  \n",
       "2        1000.0    1000.0    1000.0    5000.0        0  \n",
       "3        1200.0    1100.0    1069.0    1000.0        0  \n",
       "4       10000.0    9000.0     689.0     679.0        0  \n",
       "...         ...       ...       ...       ...      ...  \n",
       "29995    5003.0    3047.0    5000.0    1000.0        0  \n",
       "29996    8998.0     129.0       0.0       0.0        0  \n",
       "29997   22000.0    4200.0    2000.0    3100.0        1  \n",
       "29998    1178.0    1926.0   52964.0    1804.0        1  \n",
       "29999    1430.0    1000.0    1000.0    1000.0        1  \n",
       "\n",
       "[30000 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the Excel file from the URL using pandas\n",
    "df = pd.read_csv('./data/UCI_Credit_Card_modified.csv')\n",
    "# ID column has no use, so lets drop it\n",
    "df = df.drop('ID', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f460c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 24 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   LIMIT_BAL  30000 non-null  float64\n",
      " 1   SEX        30000 non-null  int64  \n",
      " 2   EDUCATION  30000 non-null  int64  \n",
      " 3   MARRIAGE   30000 non-null  int64  \n",
      " 4   AGE        30000 non-null  int64  \n",
      " 5   PAY_0      30000 non-null  int64  \n",
      " 6   PAY_2      30000 non-null  int64  \n",
      " 7   PAY_3      30000 non-null  int64  \n",
      " 8   PAY_4      30000 non-null  int64  \n",
      " 9   PAY_5      30000 non-null  int64  \n",
      " 10  PAY_6      30000 non-null  int64  \n",
      " 11  BILL_AMT1  30000 non-null  float64\n",
      " 12  BILL_AMT2  30000 non-null  float64\n",
      " 13  BILL_AMT3  30000 non-null  float64\n",
      " 14  BILL_AMT4  30000 non-null  float64\n",
      " 15  BILL_AMT5  30000 non-null  float64\n",
      " 16  BILL_AMT6  30000 non-null  float64\n",
      " 17  PAY_AMT1   30000 non-null  float64\n",
      " 18  PAY_AMT2   30000 non-null  float64\n",
      " 19  PAY_AMT3   30000 non-null  float64\n",
      " 20  PAY_AMT4   30000 non-null  float64\n",
      " 21  PAY_AMT5   30000 non-null  float64\n",
      " 22  PAY_AMT6   30000 non-null  float64\n",
      " 23  DEFAULT    30000 non-null  int64  \n",
      "dtypes: float64(13), int64(11)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e93c55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define X and y using iloc\n",
    "X = df.iloc[:, :-1]  # Select all columns except the last one\n",
    "y = df.iloc[:, -1]  # Select the last column as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6da297a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(X, columns=['LIMIT_BAL',\n",
    "                               'SEX',\n",
    "                               'EDUCATION',\n",
    "                               'MARRIAGE',\n",
    "                               'AGE',\n",
    "                               'PAY_0',\n",
    "                               'PAY_2',\n",
    "                               'PAY_3',\n",
    "                               'PAY_4',\n",
    "                               'PAY_5',\n",
    "                               'PAY_6',\n",
    "                               'BILL_AMT1',\n",
    "                               'BILL_AMT2',\n",
    "                               'BILL_AMT3',\n",
    "                               'BILL_AMT4',\n",
    "                               'BILL_AMT5',\n",
    "                               'BILL_AMT6',\n",
    "                               'PAY_AMT1',\n",
    "                               'PAY_AMT2',\n",
    "                               'PAY_AMT3',\n",
    "                               'PAY_AMT4',\n",
    "                               'PAY_AMT5',\n",
    "                               'PAY_AMT6'])\n",
    "df2 = pd.DataFrame(y, columns=['DEFAULT'])\n",
    "final_df = pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc67ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(final_df[['LIMIT_BAL',\n",
    "                                        'SEX',\n",
    "                                         'EDUCATION',\n",
    "                                         'MARRIAGE',\n",
    "                                         'AGE',\n",
    "                                         'PAY_0',\n",
    "                                         'PAY_2',\n",
    "                                         'PAY_3',\n",
    "                                         'PAY_4',\n",
    "                                         'PAY_5',\n",
    "                                         'PAY_6',\n",
    "                                         'BILL_AMT1',\n",
    "                                         'BILL_AMT2',\n",
    "                                         'BILL_AMT3',\n",
    "                                         'BILL_AMT4',\n",
    "                                         'BILL_AMT5',\n",
    "                                         'BILL_AMT6',\n",
    "                                         'PAY_AMT1',\n",
    "                                         'PAY_AMT2',\n",
    "                                         'PAY_AMT3',\n",
    "                                         'PAY_AMT4',\n",
    "                                         'PAY_AMT5',\n",
    "                                         'PAY_AMT6']], final_df['DEFAULT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b579c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46728, 23)\n",
      "23364\n",
      "23364\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(len(y[y == 0]))\n",
    "print(len(y[y == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fb80ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a228e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['SEX',\n",
    "                    'EDUCATION',\n",
    "                    'MARRIAGE',\n",
    "                    'PAY_0',\n",
    "                    'PAY_2',\n",
    "                    'PAY_3',\n",
    "                    'PAY_4',\n",
    "                    'PAY_5',\n",
    "                    'PAY_6']\n",
    "numerical_cols = ['LIMIT_BAL',\n",
    "                    'AGE',\n",
    "                    'BILL_AMT1',\n",
    "                    'BILL_AMT2',\n",
    "                    'BILL_AMT3',\n",
    "                    'BILL_AMT4',\n",
    "                    'BILL_AMT5',\n",
    "                    'BILL_AMT6',\n",
    "                    'PAY_AMT1',\n",
    "                    'PAY_AMT2',\n",
    "                    'PAY_AMT3',\n",
    "                    'PAY_AMT4',\n",
    "                    'PAY_AMT5',\n",
    "                    'PAY_AMT6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdaf8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature Engineering Automation\n",
    "## Numerical Pipelines\n",
    "num_pipeline=Pipeline(\n",
    "    steps=[\n",
    "        ('imputer',SimpleImputer(strategy='median')), ##Missing Values\n",
    "        ('scaler',StandardScaler()) ## feature Scaling\n",
    "        ]\n",
    "    )\n",
    "\n",
    "#categorical Pipeline\n",
    "cat_pipeline=Pipeline(\n",
    "    steps=[\n",
    "        ('imputer',SimpleImputer(strategy='most_frequent')), ## handling Missing values\n",
    "        ]\n",
    "    )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "108ce5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor=ColumnTransformer([\n",
    "    ('num_pipeline',num_pipeline,numerical_cols),\n",
    "    ('cat_pipeline',cat_pipeline,categorical_cols)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cd1fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=preprocessor.fit_transform(X_train)\n",
    "X_test=preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca58891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Training Automation\n",
    "models={\n",
    "    'Random Forest':RandomForestClassifier(),\n",
    "    'XGBClassifier':XGBClassifier(),\n",
    "    'SVC':SVC(),\n",
    "    'IsolationForest' :IsolationForest(),\n",
    "    'MLPClassifier' :MLPClassifier(activation='relu')\n",
    "\n",
    "}\n",
    "\n",
    "def evaluate_model(X_train,y_train,X_test,y_test,models):\n",
    "    \n",
    "    report = {}\n",
    "    for i in range(len(models)):\n",
    "        model = list(models.values())[i]\n",
    "        # Train model\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "            \n",
    "\n",
    "        # Predict Testing data\n",
    "        y_test_pred =model.predict(X_test)\n",
    "\n",
    "        # Get accuracy for test data prediction\n",
    "       \n",
    "        test_model_score = accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "        report[list(models.keys())[i]] =  test_model_score\n",
    "            \n",
    "\n",
    "            \n",
    "    return report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe1bc55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': 0.8420714744275626,\n",
       " 'XGBClassifier': 0.8245238604750695,\n",
       " 'SVC': 0.7558313717098224,\n",
       " 'IsolationForest': 0.4559169698266638,\n",
       " 'MLPClassifier': 0.7808688208859406}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(X_train,y_train,X_test,y_test,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9246bf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.836 total time=  13.7s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.835 total time=  18.6s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.841 total time=  18.8s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.830 total time=  18.9s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=2, n_estimators=100;, score=0.836 total time=  23.3s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=2, n_estimators=200;, score=0.836 total time=  39.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=2, n_estimators=200;, score=0.838 total time=  42.2s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.834 total time=  19.9s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=2, n_estimators=200;, score=0.840 total time=  43.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.828 total time=  24.5s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=2, n_estimators=200;, score=0.833 total time=  46.1s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=2, n_estimators=200;, score=0.838 total time=  47.6s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=2, n_estimators=300;, score=0.834 total time=  55.1s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=2, n_estimators=300;, score=0.840 total time=  56.8s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.826 total time=  16.4s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.833 total time=  21.4s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=5, n_estimators=100;, score=0.835 total time=  19.4s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=2, n_estimators=300;, score=0.836 total time=  59.8s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=2, n_estimators=300;, score=0.833 total time=  57.1s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=2, n_estimators=300;, score=0.841 total time= 1.0min\n",
      "[CV 2/5] END max_depth=None, min_samples_split=5, n_estimators=200;, score=0.836 total time=  36.1s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=5, n_estimators=200;, score=0.834 total time=  37.9s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=5, n_estimators=200;, score=0.834 total time=  39.0s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=5, n_estimators=200;, score=0.834 total time=  47.3s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.826 total time=  18.9s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=5, n_estimators=200;, score=0.829 total time=  40.8s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.824 total time=  18.4s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.828 total time=  18.8s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.826 total time=  15.1s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=10, n_estimators=100;, score=0.820 total time=  16.0s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=5, n_estimators=300;, score=0.839 total time=  55.5s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=5, n_estimators=300;, score=0.833 total time= 1.1min\n",
      "[CV 4/5] END max_depth=None, min_samples_split=5, n_estimators=300;, score=0.835 total time=  59.3s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=5, n_estimators=300;, score=0.830 total time=  47.6s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=5, n_estimators=300;, score=0.833 total time= 1.0min\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=0.753 total time=   6.8s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=0.753 total time=   8.8s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=10, n_estimators=200;, score=0.825 total time=  40.7s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=0.749 total time=   5.3s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=10, n_estimators=200;, score=0.829 total time=  37.8s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=10, n_estimators=200;, score=0.830 total time=  41.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=0.753 total time=   6.7s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=10, n_estimators=200;, score=0.828 total time=  39.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=100;, score=0.749 total time=   6.8s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=10, n_estimators=200;, score=0.818 total time=  42.4s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=0.747 total time=  10.3s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=0.753 total time=  14.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=0.751 total time=  15.6s\n",
      "[CV 1/5] END max_depth=None, min_samples_split=10, n_estimators=300;, score=0.825 total time=  50.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=0.748 total time=  16.8s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=200;, score=0.748 total time=  16.3s\n",
      "[CV 2/5] END max_depth=None, min_samples_split=10, n_estimators=300;, score=0.830 total time=  51.2s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=0.746 total time=   5.6s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=0.751 total time=   9.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=0.748 total time=   7.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=0.748 total time=  23.2s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=0.756 total time=  12.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=100;, score=0.750 total time=   7.1s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=0.755 total time=  25.4s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=0.747 total time=   9.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=0.745 total time=  23.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=0.749 total time=  24.2s\n",
      "[CV 3/5] END max_depth=None, min_samples_split=10, n_estimators=300;, score=0.827 total time= 1.0min\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=0.747 total time=  29.5s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=0.755 total time=  17.7s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=0.748 total time=  16.0s\n",
      "[CV 4/5] END max_depth=None, min_samples_split=10, n_estimators=300;, score=0.827 total time= 1.0min\n",
      "[CV 2/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=0.756 total time=   5.4s\n",
      "[CV 5/5] END max_depth=None, min_samples_split=10, n_estimators=300;, score=0.820 total time= 1.1min\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=0.749 total time=  27.1s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=0.753 total time=   8.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=0.749 total time=   7.1s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=0.751 total time=   7.5s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=5, n_estimators=300;, score=0.755 total time=  18.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=10, n_estimators=100;, score=0.747 total time=   6.7s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=5, n_estimators=300;, score=0.752 total time=  24.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=200;, score=0.749 total time=  25.3s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=5, n_estimators=300;, score=0.747 total time=  25.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=5, n_estimators=300;, score=0.748 total time=  27.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=0.750 total time=  15.2s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=5, n_estimators=300;, score=0.747 total time=  23.4s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=0.747 total time=  12.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=0.747 total time=  13.6s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=0.755 total time=  16.9s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=10, n_estimators=200;, score=0.747 total time=  15.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=2, n_estimators=100;, score=0.786 total time=  11.8s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=10, n_estimators=300;, score=0.755 total time=  21.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=2, n_estimators=100;, score=0.785 total time=  12.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=2, n_estimators=100;, score=0.788 total time=  12.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=10, n_estimators=300;, score=0.747 total time=  22.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=10, n_estimators=300;, score=0.752 total time=  25.4s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=10, n_estimators=300;, score=0.747 total time=  27.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=2, n_estimators=100;, score=0.790 total time=  22.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=2, n_estimators=100;, score=0.779 total time=  23.3s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=10, n_estimators=300;, score=0.748 total time=  28.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=2, n_estimators=200;, score=0.788 total time=  29.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=5, n_estimators=100;, score=0.789 total time=  10.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=2, n_estimators=200;, score=0.783 total time=  32.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=2, n_estimators=200;, score=0.785 total time=  26.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=5, n_estimators=100;, score=0.785 total time=  15.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=2, n_estimators=200;, score=0.790 total time=  28.9s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=0.785 total time=  30.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=2, n_estimators=200;, score=0.781 total time=  31.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=5, n_estimators=100;, score=0.787 total time=  10.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=5, n_estimators=100;, score=0.786 total time=   9.3s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=0.786 total time=  33.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=5, n_estimators=100;, score=0.781 total time=  13.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=0.787 total time=  38.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=0.787 total time=  36.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=5, n_estimators=200;, score=0.780 total time=  17.8s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=0.781 total time=  42.5s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=5, n_estimators=200;, score=0.788 total time=  26.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=5, n_estimators=200;, score=0.788 total time=  24.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=5, n_estimators=200;, score=0.785 total time=  31.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=5, n_estimators=200;, score=0.785 total time=  29.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=10, n_estimators=100;, score=0.783 total time=  16.7s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=10, n_estimators=100;, score=0.785 total time=  10.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=10, n_estimators=100;, score=0.785 total time=  12.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=10, n_estimators=100;, score=0.785 total time=  11.3s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=5, n_estimators=300;, score=0.784 total time=  30.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=10, n_estimators=100;, score=0.780 total time=  13.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=5, n_estimators=300;, score=0.782 total time=  44.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=5, n_estimators=300;, score=0.787 total time=  40.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=5, n_estimators=300;, score=0.787 total time=  45.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=5, n_estimators=300;, score=0.779 total time=  43.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=10, n_estimators=200;, score=0.785 total time=  26.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=10, n_estimators=200;, score=0.784 total time=  29.9s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=10, n_estimators=200;, score=0.781 total time=  21.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=10, n_estimators=200;, score=0.786 total time=  28.8s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=10, n_estimators=200;, score=0.786 total time=  28.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=10, n_estimators=300;, score=0.781 total time=  27.9s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=10, n_estimators=300;, score=0.783 total time=  25.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=10, n_estimators=300;, score=0.785 total time=  28.5s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=10, n_estimators=300;, score=0.780 total time=  21.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=10, n_estimators=300;, score=0.788 total time=  23.9s\n",
      "Best Random Forest Hyperparameters:\n",
      "{'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "\n",
      "Training XGBClassifier...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.778 total time=   8.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.785 total time=   8.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.778 total time=   9.9s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.779 total time=  12.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.801 total time=  16.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.798 total time=  20.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.790 total time=  20.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.793 total time=  21.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.790 total time=  21.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.779 total time=  22.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.796 total time=  28.4s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.802 total time=  12.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=3, n_estimators=200;, score=0.794 total time=  30.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.804 total time=  28.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.799 total time=  25.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.804 total time=  18.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.799 total time=  30.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=3, n_estimators=300;, score=0.798 total time=  29.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.791 total time=  23.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.813 total time=  21.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.810 total time=  23.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.797 total time=  27.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.816 total time=  15.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.807 total time=  32.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.809 total time=  36.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=200;, score=0.815 total time=  36.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.816 total time=  27.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.814 total time=  27.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.814 total time=  25.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=100;, score=0.807 total time=  15.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.814 total time=  43.3s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.815 total time=  50.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.819 total time=  58.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.818 total time=  58.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=300;, score=0.816 total time=  58.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.734 total time=   9.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.738 total time=  10.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.829 total time=  49.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.827 total time=  49.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.731 total time=   8.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.734 total time=  11.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.826 total time=  54.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=100;, score=0.735 total time=   8.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.833 total time=  47.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.820 total time=  52.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=200;, score=0.823 total time=  53.1s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.752 total time=  13.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.746 total time=  18.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.831 total time= 1.0min\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.749 total time=  14.7s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.749 total time=  19.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=200;, score=0.752 total time=  19.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=3, n_estimators=300;, score=0.759 total time=  23.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.831 total time= 1.1min\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.751 total time=  15.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.754 total time=  15.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=3, n_estimators=300;, score=0.758 total time=  30.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.832 total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.753 total time=  15.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.753 total time=  17.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=3, n_estimators=300;, score=0.761 total time=  31.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=7, n_estimators=300;, score=0.823 total time= 1.0min\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=3, n_estimators=300;, score=0.759 total time=  29.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=3, n_estimators=300;, score=0.758 total time=  28.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=100;, score=0.751 total time=  13.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.771 total time=  21.4s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.769 total time=  25.6s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.765 total time=  29.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=0.768 total time=  20.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.764 total time=  30.2s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=0.768 total time=  21.3s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=200;, score=0.768 total time=  33.1s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=5, n_estimators=300;, score=0.772 total time=  41.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=0.771 total time=  23.4s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=5, n_estimators=300;, score=0.777 total time=  46.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=0.769 total time=  33.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=5, n_estimators=300;, score=0.773 total time=  48.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=100;, score=0.768 total time=  28.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=5, n_estimators=300;, score=0.776 total time=  50.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=5, n_estimators=300;, score=0.776 total time=  58.4s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=0.782 total time=  32.0s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.708 total time=   8.5s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.710 total time=   6.0s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.713 total time=   7.8s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.715 total time=   8.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=0.782 total time=  43.3s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=100;, score=0.710 total time=   6.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=0.780 total time=  45.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=0.780 total time=  44.9s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.714 total time=  14.4s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.713 total time=  11.9s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.713 total time=  18.2s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=200;, score=0.778 total time=  46.4s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.712 total time=  24.6s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=200;, score=0.717 total time=  24.2s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=3, n_estimators=300;, score=0.718 total time=  18.1s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=3, n_estimators=300;, score=0.719 total time=  27.5s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=3, n_estimators=300;, score=0.719 total time=  30.2s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=0.731 total time=  16.1s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=0.735 total time=  17.6s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=3, n_estimators=300;, score=0.720 total time=  32.8s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=3, n_estimators=300;, score=0.718 total time=  35.2s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=0.733 total time=  19.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=7, n_estimators=300;, score=0.785 total time= 1.3min\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=7, n_estimators=300;, score=0.791 total time= 1.3min\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=0.738 total time=  24.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=7, n_estimators=300;, score=0.789 total time= 1.3min\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=100;, score=0.738 total time=  19.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=7, n_estimators=300;, score=0.785 total time= 1.3min\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=7, n_estimators=300;, score=0.791 total time= 1.4min\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=0.734 total time=  36.3s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=0.738 total time=  32.6s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=0.738 total time=  41.8s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=0.738 total time=  35.6s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=200;, score=0.741 total time=  38.0s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=7, n_estimators=100;, score=0.747 total time=  31.8s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=7, n_estimators=100;, score=0.752 total time=  28.1s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=5, n_estimators=300;, score=0.741 total time=  39.7s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=7, n_estimators=100;, score=0.746 total time=  26.9s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=7, n_estimators=100;, score=0.753 total time=  32.3s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=5, n_estimators=300;, score=0.741 total time= 1.0min\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=7, n_estimators=100;, score=0.750 total time=  36.3s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=5, n_estimators=300;, score=0.738 total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=5, n_estimators=300;, score=0.740 total time= 1.1min\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=5, n_estimators=300;, score=0.742 total time= 1.1min\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=7, n_estimators=200;, score=0.752 total time=  52.6s\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=7, n_estimators=200;, score=0.754 total time=  51.5s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=7, n_estimators=200;, score=0.758 total time=  46.5s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=7, n_estimators=200;, score=0.754 total time=  55.6s\n",
      "[CV 1/5] END learning_rate=0.001, max_depth=7, n_estimators=300;, score=0.755 total time=  51.6s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=7, n_estimators=200;, score=0.758 total time= 1.2min\n",
      "[CV 2/5] END learning_rate=0.001, max_depth=7, n_estimators=300;, score=0.757 total time=  51.6s\n",
      "[CV 3/5] END learning_rate=0.001, max_depth=7, n_estimators=300;, score=0.762 total time=  56.5s\n",
      "[CV 5/5] END learning_rate=0.001, max_depth=7, n_estimators=300;, score=0.763 total time=  55.7s\n",
      "[CV 4/5] END learning_rate=0.001, max_depth=7, n_estimators=300;, score=0.758 total time= 1.1min\n",
      "Best XGBClassifier Hyperparameters:\n",
      "{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}\n",
      "\n",
      "\n",
      "Training SVC...\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.762 total time= 2.6min\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.760 total time= 2.7min\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.761 total time= 2.9min\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.762 total time= 2.9min\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.763 total time= 3.1min\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.723 total time= 3.8min\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.725 total time= 4.4min\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.728 total time= 4.4min\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.720 total time= 4.4min\n",
      "[CV 2/5] END ....C=1, gamma=auto, kernel=linear;, score=0.725 total time= 4.5min\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.725 total time= 4.5min\n",
      "[CV 1/5] END ....C=1, gamma=auto, kernel=linear;, score=0.720 total time= 4.6min\n",
      "[CV 2/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.762 total time= 2.4min\n",
      "[CV 1/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.765 total time= 2.7min\n",
      "[CV 3/5] END ....C=1, gamma=auto, kernel=linear;, score=0.723 total time= 3.8min\n",
      "[CV 3/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.767 total time= 2.7min\n",
      "[CV 5/5] END ....C=1, gamma=auto, kernel=linear;, score=0.728 total time= 3.7min\n",
      "[CV 5/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.765 total time= 2.3min\n",
      "[CV 4/5] END ....C=1, gamma=auto, kernel=linear;, score=0.725 total time= 4.4min\n",
      "[CV 4/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.763 total time= 2.8min\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.771 total time= 3.7min\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.768 total time= 3.1min\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.773 total time= 3.5min\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.773 total time= 3.5min\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.775 total time= 3.9min\n",
      "[CV 1/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.774 total time= 4.0min\n",
      "[CV 2/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.776 total time= 3.9min\n",
      "[CV 3/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.778 total time= 2.9min\n",
      "[CV 4/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.772 total time= 2.7min\n",
      "[CV 5/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.777 total time= 2.4min\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.725 total time=16.5min\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.720 total time=17.8min\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.723 total time=18.1min\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.725 total time=18.5min\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.728 total time=18.0min\n",
      "[CV 2/5] END ...C=10, gamma=auto, kernel=linear;, score=0.725 total time=16.8min\n",
      "[CV 1/5] END ...C=10, gamma=auto, kernel=linear;, score=0.720 total time=17.0min\n",
      "[CV 4/5] END ...C=10, gamma=auto, kernel=linear;, score=0.725 total time=15.6min\n",
      "[CV 5/5] END ...C=10, gamma=auto, kernel=linear;, score=0.728 total time=15.9min\n",
      "[CV 3/5] END ...C=10, gamma=auto, kernel=linear;, score=0.723 total time=16.9min\n",
      "[CV 1/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.776 total time= 8.8min\n",
      "[CV 2/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.785 total time= 8.8min\n",
      "[CV 4/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.772 total time= 8.4min\n",
      "[CV 3/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.785 total time= 8.8min\n",
      "[CV 5/5] END ....C=100, gamma=scale, kernel=rbf;, score=0.782 total time= 8.6min\n",
      "[CV 1/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.778 total time= 9.9min\n",
      "[CV 2/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.786 total time= 9.9min\n",
      "[CV 3/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.787 total time= 9.9min\n",
      "[CV 4/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.773 total time= 9.8min\n",
      "[CV 5/5] END .....C=100, gamma=auto, kernel=rbf;, score=0.784 total time= 9.1min\n",
      "[CV 1/5] END .C=100, gamma=scale, kernel=linear;, score=0.720 total time=83.7min\n",
      "[CV 2/5] END .C=100, gamma=scale, kernel=linear;, score=0.725 total time=82.5min\n",
      "[CV 3/5] END .C=100, gamma=scale, kernel=linear;, score=0.724 total time=82.6min\n",
      "[CV 5/5] END .C=100, gamma=scale, kernel=linear;, score=0.728 total time=81.6min\n",
      "[CV 4/5] END .C=100, gamma=scale, kernel=linear;, score=0.725 total time=83.2min\n",
      "[CV 1/5] END ..C=100, gamma=auto, kernel=linear;, score=0.720 total time=80.7min\n",
      "[CV 2/5] END ..C=100, gamma=auto, kernel=linear;, score=0.725 total time=80.2min\n",
      "[CV 4/5] END ..C=100, gamma=auto, kernel=linear;, score=0.725 total time=75.2min\n",
      "[CV 5/5] END ..C=100, gamma=auto, kernel=linear;, score=0.728 total time=75.5min\n",
      "[CV 3/5] END ..C=100, gamma=auto, kernel=linear;, score=0.724 total time=76.9min\n",
      "Best SVC Hyperparameters:\n",
      "{'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "Training IsolationForest...\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 2/5] END contamination=0.05, n_estimators=100;, score=0.483 total time=   2.1s\n",
      "[CV 1/5] END contamination=0.05, n_estimators=100;, score=0.479 total time=   3.7s\n",
      "[CV 4/5] END contamination=0.05, n_estimators=100;, score=0.472 total time=   2.3s\n",
      "[CV 3/5] END contamination=0.05, n_estimators=100;, score=0.480 total time=   4.0s\n",
      "[CV 5/5] END contamination=0.05, n_estimators=200;, score=0.468 total time=   4.7s\n",
      "[CV 5/5] END contamination=0.05, n_estimators=100;, score=0.470 total time=   3.1s\n",
      "[CV 1/5] END contamination=0.05, n_estimators=200;, score=0.479 total time=   5.4s\n",
      "[CV 2/5] END contamination=0.05, n_estimators=200;, score=0.482 total time=   6.2s\n",
      "[CV 1/5] END contamination=0.05, n_estimators=300;, score=0.479 total time=   6.8s\n",
      "[CV 1/5] END contamination=0.1, n_estimators=100;, score=0.461 total time=   2.7s\n",
      "[CV 3/5] END contamination=0.05, n_estimators=200;, score=0.481 total time=   7.8s\n",
      "[CV 2/5] END contamination=0.1, n_estimators=100;, score=0.459 total time=   3.1s\n",
      "[CV 3/5] END contamination=0.1, n_estimators=100;, score=0.460 total time=   3.1s\n",
      "[CV 4/5] END contamination=0.05, n_estimators=200;, score=0.472 total time=   8.1s\n",
      "[CV 4/5] END contamination=0.1, n_estimators=100;, score=0.449 total time=   3.1s\n",
      "[CV 5/5] END contamination=0.1, n_estimators=100;, score=0.447 total time=   2.9s\n",
      "[CV 3/5] END contamination=0.05, n_estimators=300;, score=0.482 total time=   9.3s\n",
      "[CV 2/5] END contamination=0.05, n_estimators=300;, score=0.482 total time=   9.7s\n",
      "[CV 5/5] END contamination=0.05, n_estimators=300;, score=0.470 total time=   9.1s\n",
      "[CV 1/5] END contamination=0.1, n_estimators=200;, score=0.459 total time=   5.3s\n",
      "[CV 2/5] END contamination=0.1, n_estimators=200;, score=0.464 total time=   5.4s\n",
      "[CV 4/5] END contamination=0.05, n_estimators=300;, score=0.471 total time=  11.1s\n",
      "[CV 4/5] END contamination=0.1, n_estimators=200;, score=0.450 total time=   5.5s\n",
      "[CV 5/5] END contamination=0.1, n_estimators=200;, score=0.447 total time=   5.5s\n",
      "[CV 3/5] END contamination=0.1, n_estimators=200;, score=0.462 total time=   6.3s\n",
      "[CV 2/5] END contamination=0.2, n_estimators=100;, score=0.418 total time=   2.7s\n",
      "[CV 3/5] END contamination=0.2, n_estimators=100;, score=0.418 total time=   2.9s\n",
      "[CV 1/5] END contamination=0.2, n_estimators=100;, score=0.411 total time=   3.6s\n",
      "[CV 5/5] END contamination=0.2, n_estimators=100;, score=0.409 total time=   2.8s\n",
      "[CV 4/5] END contamination=0.2, n_estimators=100;, score=0.405 total time=   3.2s\n",
      "[CV 3/5] END contamination=0.1, n_estimators=300;, score=0.461 total time=   7.8s\n",
      "[CV 1/5] END contamination=0.1, n_estimators=300;, score=0.458 total time=   8.8s\n",
      "[CV 2/5] END contamination=0.1, n_estimators=300;, score=0.462 total time=   8.6s\n",
      "[CV 5/5] END contamination=0.1, n_estimators=300;, score=0.448 total time=   8.2s\n",
      "[CV 4/5] END contamination=0.1, n_estimators=300;, score=0.450 total time=   8.4s\n",
      "[CV 1/5] END contamination=0.2, n_estimators=200;, score=0.411 total time=   5.1s\n",
      "[CV 2/5] END contamination=0.2, n_estimators=200;, score=0.408 total time=   5.4s\n",
      "[CV 3/5] END contamination=0.2, n_estimators=200;, score=0.417 total time=   5.1s\n",
      "[CV 5/5] END contamination=0.2, n_estimators=200;, score=0.404 total time=   4.6s\n",
      "[CV 4/5] END contamination=0.2, n_estimators=200;, score=0.403 total time=   5.0s\n",
      "[CV 1/5] END contamination=0.2, n_estimators=300;, score=0.416 total time=   5.6s\n",
      "[CV 5/5] END contamination=0.2, n_estimators=300;, score=0.397 total time=   4.6s\n",
      "[CV 2/5] END contamination=0.2, n_estimators=300;, score=0.415 total time=   6.1s\n",
      "[CV 4/5] END contamination=0.2, n_estimators=300;, score=0.404 total time=   5.0s\n",
      "[CV 3/5] END contamination=0.2, n_estimators=300;, score=0.423 total time=   5.6s\n",
      "Best IsolationForest Hyperparameters:\n",
      "{'contamination': 0.05, 'n_estimators': 100}\n",
      "\n",
      "\n",
      "Training MLPClassifier...\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 3/5] END alpha=0.0001, hidden_layer_sizes=(100,);, score=0.775 total time=  36.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, hidden_layer_sizes=(100,);, score=0.769 total time=  43.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, hidden_layer_sizes=(100,);, score=0.779 total time=  47.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, hidden_layer_sizes=(100,);, score=0.777 total time=  48.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, hidden_layer_sizes=(100,);, score=0.775 total time=  53.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, hidden_layer_sizes=(100,);, score=0.781 total time=  48.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, hidden_layer_sizes=(100, 100);, score=0.775 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, hidden_layer_sizes=(100, 100);, score=0.772 total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.001, hidden_layer_sizes=(100,);, score=0.777 total time=  53.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, hidden_layer_sizes=(100, 100);, score=0.774 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, hidden_layer_sizes=(100, 100);, score=0.776 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, hidden_layer_sizes=(100, 100);, score=0.775 total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.001, hidden_layer_sizes=(100,);, score=0.772 total time=  44.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.001, hidden_layer_sizes=(100,);, score=0.772 total time=  46.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.001, hidden_layer_sizes=(100,);, score=0.777 total time=  50.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0001, hidden_layer_sizes=(100, 100, 100);, score=0.776 total time= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.0001, hidden_layer_sizes=(100, 100, 100);, score=0.776 total time= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0001, hidden_layer_sizes=(100, 100, 100);, score=0.775 total time= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0001, hidden_layer_sizes=(100, 100, 100);, score=0.774 total time= 3.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, hidden_layer_sizes=(100, 100);, score=0.778 total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.001, hidden_layer_sizes=(100, 100);, score=0.781 total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.001, hidden_layer_sizes=(100, 100);, score=0.785 total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0001, hidden_layer_sizes=(100, 100, 100);, score=0.772 total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.001, hidden_layer_sizes=(100, 100);, score=0.780 total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.01, hidden_layer_sizes=(100,);, score=0.772 total time=  54.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.001, hidden_layer_sizes=(100, 100);, score=0.777 total time= 2.6min\n",
      "[CV 4/5] END alpha=0.01, hidden_layer_sizes=(100,);, score=0.774 total time=  48.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.01, hidden_layer_sizes=(100,);, score=0.775 total time=  57.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.01, hidden_layer_sizes=(100,);, score=0.777 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.01, hidden_layer_sizes=(100,);, score=0.777 total time=  56.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.001, hidden_layer_sizes=(100, 100, 100);, score=0.773 total time= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.001, hidden_layer_sizes=(100, 100, 100);, score=0.777 total time= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.01, hidden_layer_sizes=(100, 100);, score=0.777 total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.01, hidden_layer_sizes=(100, 100);, score=0.775 total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.01, hidden_layer_sizes=(100, 100);, score=0.780 total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.01, hidden_layer_sizes=(100, 100);, score=0.787 total time= 2.8min\n",
      "[CV 4/5] END alpha=0.001, hidden_layer_sizes=(100, 100, 100);, score=0.774 total time= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.001, hidden_layer_sizes=(100, 100, 100);, score=0.767 total time= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.001, hidden_layer_sizes=(100, 100, 100);, score=0.769 total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.01, hidden_layer_sizes=(100, 100);, score=0.780 total time= 2.9min\n",
      "[CV 1/5] END alpha=0.01, hidden_layer_sizes=(100, 100, 100);, score=0.770 total time= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.01, hidden_layer_sizes=(100, 100, 100);, score=0.777 total time= 3.5min\n",
      "[CV 3/5] END alpha=0.01, hidden_layer_sizes=(100, 100, 100);, score=0.770 total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.01, hidden_layer_sizes=(100, 100, 100);, score=0.780 total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milan/anaconda3/envs/ml/lib/python3.10/site-packages/scikit_learn-1.2.2-py3.10-linux-x86_64.egg/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.01, hidden_layer_sizes=(100, 100, 100);, score=0.774 total time= 3.0min\n",
      "Best MLPClassifier Hyperparameters:\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (100, 100)}\n",
      "\n",
      "\n",
      "Random Forest Accuracy: 0.8445324202867537\n",
      "XGBClassifier Accuracy: 0.8341536486197304\n",
      "SVC Accuracy: 0.7778728867964905\n",
      "IsolationForest Accuracy: 0.4754975390541408\n",
      "MLPClassifier Accuracy: 0.7826877808688208\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, models, param_grids):\n",
    "    report = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Training {model_name}...\")\n",
    "        \n",
    "        # Perform hyperparameter tuning using GridSearchCV\n",
    "        grid_search = GridSearchCV(model, param_grid=param_grids[model_name], cv=5, verbose=3, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # Predict Testing data\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Get accuracy for test data prediction\n",
    "        test_model_score = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        report[model_name] = test_model_score\n",
    "        \n",
    "        # Print the best model's hyperparameters\n",
    "        print(f\"Best {model_name} Hyperparameters:\")\n",
    "        print(grid_search.best_params_)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 5, 10],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.1, 0.01, 0.001]\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': [1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'IsolationForest': {\n",
    "        'contamination': [0.05, 0.1, 0.2],\n",
    "        'n_estimators': [100, 200, 300]\n",
    "    },\n",
    "    'MLPClassifier': {\n",
    "        'hidden_layer_sizes': [(100,), (100, 100), (100, 100, 100)],\n",
    "        'alpha': [0.0001, 0.001, 0.01]\n",
    "    }\n",
    "}\n",
    "\n",
    "report = evaluate_model(X_train, y_train, X_test, y_test, models, param_grids)\n",
    "\n",
    "# Print the evaluation report\n",
    "for model_name, accuracy in report.items():\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "127e48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see the best model is Random forest with hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "570b9bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      4664\n",
      "           1       0.86      0.82      0.84      4682\n",
      "\n",
      "    accuracy                           0.84      9346\n",
      "   macro avg       0.84      0.84      0.84      9346\n",
      "weighted avg       0.84      0.84      0.84      9346\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a new Random Forest model with the best parameters\n",
    "rf_model = RandomForestClassifier(max_depth= None, min_samples_split= 2, n_estimators= 200)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830893fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
